"""
KPI íŒŒì´í”„ë¼ì¸ End-to-End í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

Usage:
    python test_kpi_pipeline.py <pdf_file_path>
    
Example:
    python test_kpi_pipeline.py "Data/ë³´í—˜ì‚¬_KPI_ìë£Œ.pdf"
"""
import sys
import json
import os
import codecs
from pathlib import Path
from dotenv import load_dotenv

# Windows CMDì—ì„œ UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == "win32":
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.buffer, "strict")
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.buffer, "strict")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python Pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from app.domain.kpi import (
    KPIVisionService,
    normalize_kpi_document,
    get_normalization_stats,
    build_kpi_chunks,
    get_chunk_statistics,
    enhance_chunks_with_metadata,
    get_metadata_summary
)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # .env íŒŒì¼ ë¡œë“œ
    load_dotenv()
    
    # ëª…ë ¹í–‰ ì¸ì í™•ì¸
    if len(sys.argv) < 2:
        print("=" * 70)
        print("KPI íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
        print("=" * 70)
        print()
        print("ì‚¬ìš©ë²•: python test_kpi_pipeline.py <pdf_file_path>")
        print()
        print("ì˜ˆì‹œ:")
        print('  python test_kpi_pipeline.py "Data/ë³´í—˜ì‚¬_KPI_ìë£Œ.pdf"')
        print('  python test_kpi_pipeline.py "Data/KPI_PDF.pdf"')
        print()
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(pdf_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        sys.exit(1)
    
    # OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print("=" * 70)
    print("ğŸš€ KPI íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 70)
    print(f"ğŸ“‚ íŒŒì¼: {pdf_path}")
    print()
    
    try:
        # ========================================
        # Step 1: PDF â†’ Vision â†’ Raw JSON
        # ========================================
        print("=" * 70)
        print("â³ Step 1: Vision APIë¡œ PDF ì²˜ë¦¬ ì¤‘...")
        print("=" * 70)
        
        service = KPIVisionService(api_key=api_key)
        raw_doc = service.process_pdf(pdf_path)
        
        print(f"ğŸ“„ ë¬¸ì„œ ì œëª©: {raw_doc.title}")
        print(f"ğŸ“„ ì´ í˜ì´ì§€: {raw_doc.total_pages}")
        print(f"ğŸ“„ ì²˜ë¦¬ëœ í˜ì´ì§€: {len(raw_doc.pages)}")
        print()
        
        # ========================================
        # Step 2: Raw JSON â†’ CanonicalKPI
        # ========================================
        print("=" * 70)
        print("â³ Step 2: Canonical KPI ë³€í™˜ ì¤‘...")
        print("=" * 70)
        
        canonical_kpis = normalize_kpi_document(raw_doc)
        
        # ì •ê·œí™” í†µê³„
        norm_stats = get_normalization_stats(canonical_kpis)
        print(f"ğŸ“Š ì´ KPI ìˆ˜: {norm_stats['total_kpis']}")
        print(f"ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„:")
        for category, count in norm_stats['by_category'].items():
            print(f"   - {category}: {count}ê°œ")
        print(f"ğŸ“Š í‘œ í¬í•¨ KPI: {norm_stats['with_table']}ê°œ")
        print(f"ğŸ“Š ì¦ê° ì •ë³´ í¬í•¨: {norm_stats['with_delta']}ê°œ")
        print()
        
        # ========================================
        # Step 3: CanonicalKPI â†’ ì²­í¬
        # ========================================
        print("=" * 70)
        print("â³ Step 3: ì²­í‚¹ ìƒì„± ì¤‘...")
        print("=" * 70)
        
        chunks = build_kpi_chunks(canonical_kpis)
        
        # ì²­í¬ í†µê³„
        chunk_stats = get_chunk_statistics(chunks)
        print(f"ğŸ“Š ì´ ì²­í¬ ìˆ˜: {chunk_stats['total_chunks']}")
        print(f"ğŸ“Š í‰ê·  ê¸¸ì´: {chunk_stats['avg_text_length']:.0f}ì")
        print(f"ğŸ“Š ìµœëŒ€ ê¸¸ì´: {chunk_stats['max_text_length']}ì")
        print(f"ğŸ“Š ìµœì†Œ ê¸¸ì´: {chunk_stats['min_text_length']}ì")
        print()
        
        # ========================================
        # Step 4: ë©”íƒ€ë°ì´í„° ì¶”ê°€
        # ========================================
        print("=" * 70)
        print("â³ Step 4: ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì¤‘...")
        print("=" * 70)
        
        final_chunks = enhance_chunks_with_metadata(chunks)
        
        # ë©”íƒ€ë°ì´í„° í†µê³„
        meta_summary = get_metadata_summary(final_chunks)
        print(f"ğŸ“Š ê³ ìœ  KPI ì´ë¦„: {meta_summary['unique_kpi_names']}ê°œ")
        print(f"ğŸ“Š ê³ ìœ  ì¹´í…Œê³ ë¦¬: {meta_summary['unique_categories']}ê°œ")
        print(f"ğŸ“Š ê³ ìœ  ë‹¨ìœ„: {meta_summary['unique_units']}ê°œ")
        print()
        
        # ========================================
        # ìƒ˜í”Œ ì¶œë ¥
        # ========================================
        print("=" * 70)
        print("ğŸ“‹ ì²­í¬ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ)")
        print("=" * 70)
        
        for idx, chunk in enumerate(final_chunks[:3], 1):
            print(f"\n[ì²­í¬ #{idx}]")
            print(f"ID: {chunk['chunk_id']}")
            print(f"KPI ID: {chunk['kpi_id']}")
            print(f"í˜ì´ì§€: {chunk['page_index'] + 1}")
            print(f"íƒœê·¸: {', '.join(chunk['tags'])}")
            print(f"ë©”íƒ€ë°ì´í„°: {json.dumps(chunk['metadata'], ensure_ascii=False, indent=2)}")
            print(f"\ní…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì):")
            print(chunk['text'][:200] + "..." if len(chunk['text']) > 200 else chunk['text'])
            print("-" * 70)
        
        # ========================================
        # íŒŒì¼ ì €ì¥
        # ========================================
        print()
        print("=" * 70)
        print("ğŸ’¾ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì¤‘...")
        print("=" * 70)
        
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        pdf_filename = Path(pdf_path).stem
        
        # 1. Raw JSON ì €ì¥
        raw_output_path = output_dir / f"{pdf_filename}_kpi_raw.json"
        with open(raw_output_path, "w", encoding="utf-8") as f:
            json.dump(raw_doc.model_dump(mode='json'), f, ensure_ascii=False, indent=2, default=str)
        
        # 2. Canonical KPI ì €ì¥
        canonical_output_path = output_dir / f"{pdf_filename}_kpi_canonical.json"
        with open(canonical_output_path, "w", encoding="utf-8") as f:
            canonical_data = [kpi.model_dump(mode='json') for kpi in canonical_kpis]
            json.dump(canonical_data, f, ensure_ascii=False, indent=2, default=str)
        
        # 3. ìµœì¢… ì²­í¬ ì €ì¥
        chunks_output_path = output_dir / f"{pdf_filename}_kpi_chunks.json"
        with open(chunks_output_path, "w", encoding="utf-8") as f:
            json.dump(final_chunks, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"1. Raw JSON: {raw_output_path}")
        print(f"2. Canonical KPI: {canonical_output_path}")
        print(f"3. ìµœì¢… ì²­í¬: {chunks_output_path}")
        print()
        
        # ========================================
        # TODO: VectorDB ì—°ë™
        # ========================================
        print("=" * 70)
        print("ğŸ“ ë‹¤ìŒ ë‹¨ê³„")
        print("=" * 70)
        print("TODO: VectorDB ì—…ì„œíŠ¸ ì—°ë™ ì˜ˆì •")
        print()
        print("ì˜ˆì‹œ ì½”ë“œ:")
        print("""
import chromadb

# ChromaDB í´ë¼ì´ì–¸íŠ¸
client = chromadb.Client()
collection = client.create_collection("kpi_documents")

# ì²­í¬ ì¶”ê°€
for chunk in final_chunks:
    collection.add(
        ids=[chunk["chunk_id"]],
        documents=[chunk["text"]],
        metadatas=[chunk["metadata"]]
    )
        """)
        print()
        
        print("=" * 70)
        print("âœ… KPI íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 70)
        
    except Exception as e:
        print()
        print("=" * 70)
        print("âŒ ì˜¤ë¥˜ ë°œìƒ")
        print("=" * 70)
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
        print()
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

