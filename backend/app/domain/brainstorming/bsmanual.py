"""
ë¸Œë ˆì¸ìŠ¤í† ë° ë§¤ë‰´ì–¼ (RAG í…ŒìŠ¤íŠ¸ìš©)

RAG ì‹œìŠ¤í…œì´ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ë°ì´í„°ë¥¼ ì˜ ê²€ìƒ‰í•˜ê³  í™œìš©í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤.
ë‚˜ì¤‘ì— ì´ RAGë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ì´ë””ì–´ ì‚°ì¶œê¸°ë¥¼ êµ¬í˜„í•  ì˜ˆì •ì…ë‹ˆë‹¤.
"""
import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from datetime import datetime

# í•œê¸€ ì…ë ¥ ë²„ê·¸ ìˆ˜ì •ì„ ìœ„í•œ readline import
try:
    import readline
except ImportError:
    pass  # Windowsì—ì„œëŠ” readlineì´ ì—†ì„ ìˆ˜ ìˆìŒ

# .env íŒŒì¼ ë¡œë“œ
env_path = Path(__file__).parent.parent.parent.parent / '.env'
load_dotenv(env_path)

# í™˜ê²½ë³€ìˆ˜ ì²´í¬
if not os.getenv('OPENAI_API_KEY'):
    print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    sys.exit(1)

# ì„œë¹„ìŠ¤ ì„í¬íŠ¸
import chromadb
from chromadb.config import Settings
from openai import OpenAI
from typing import List, Dict, Optional


class BrainstormingManual:
    """ë¸Œë ˆì¸ìŠ¤í† ë° ë§¤ë‰´ì–¼ (RAG í…ŒìŠ¤íŠ¸)"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.embedding_model = os.getenv('EMBEDDING_MODEL', 'text-embedding-3-large')
        self.llm_model = os.getenv('LLM_MODEL', 'gpt-4o')
        
        # ChromaDB ì„¤ì •
        base_dir = Path(__file__).parent
        data_dir = base_dir / "data"
        self.persist_directory = str(data_dir / "chroma")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸
        self.chroma_client = chromadb.PersistentClient(
            path=self.persist_directory,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # ì»¬ë ‰ì…˜
        self.collection_name = "brainstorming_techniques"
        self.collection = self.chroma_client.get_collection(name=self.collection_name)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.conversation_history = []
        
    def _embed_query(self, query: str) -> List[float]:
        """ì§ˆë¬¸ì„ ì„ë² ë”©"""
        response = self.openai_client.embeddings.create(
            model=self.embedding_model,
            input=query,
            encoding_format="float"
        )
        return response.data[0].embedding
    
    def search_techniques(self, query: str, n_results: int = 3) -> List[Dict]:
        """ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ê²€ìƒ‰"""
        query_embedding = self._embed_query(query)
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )
        
        formatted_results = []
        for idx in range(len(results['ids'][0])):
            distance = results['distances'][0][idx]
            similarity = 1 - distance
            
            metadata = results['metadatas'][0][idx]
            document = results['documents'][0][idx]
            
            formatted_results.append({
                "chunk_id": metadata['chunk_id'],
                "title": metadata['title'],
                "content": document,
                "similarity": round(similarity, 4)
            })
        
        return formatted_results
    
    def chat(self, user_message: str) -> str:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ ì‘ë‹µ ìƒì„±
        
        Args:
            user_message: ì‚¬ìš©ìì˜ ì§ˆë¬¸/ë©”ì‹œì§€
            
        Returns:
            ì±—ë´‡ì˜ ì‘ë‹µ
        """
        # 1. ê´€ë ¨ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ê²€ìƒ‰
        relevant_techniques = self.search_techniques(user_message, n_results=3)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        if relevant_techniques:
            context = "\n\n".join([
                f"[{tech['title']}]\n{tech['content'][:300]}..."
                for tech in relevant_techniques
            ])
        else:
            context = "ê´€ë ¨ëœ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # 3. ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })
        
        # 4. GPTì—ê²Œ ì§ˆë¬¸ (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
        system_prompt = f"""ë‹¹ì‹ ì€ ë¸Œë ˆì¸ìŠ¤í† ë° ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:

{context}

ë‹µë³€ ê°€ì´ë“œ:
- ì¹œê·¼í•˜ê³  ëŒ€í™”í•˜ë“¯ì´ ë‹µë³€í•˜ì„¸ìš”
- ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
- í•„ìš”ì‹œ ì‹¤í–‰ ë°©ë²•ê³¼ ì£¼ì˜ì‚¬í•­ì„ ì•Œë ¤ì£¼ì„¸ìš”
- ì°¸ê³ í•œ ê¸°ë²•ì˜ ì´ë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”
- ê°„ê²°í•˜ì§€ë§Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”"""

        messages = [{"role": "system", "content": system_prompt}]
        
        # ìµœê·¼ 5ê°œ ëŒ€í™”ë§Œ í¬í•¨ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ)
        messages.extend(self.conversation_history[-5:])
        
        response = self.openai_client.chat.completions.create(
            model=self.llm_model,
            messages=messages,
            temperature=0.7,
            max_tokens=800
        )
        
        assistant_message = response.choices[0].message.content
        
        # 5. ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append({
            "role": "assistant",
            "content": assistant_message
        })
        
        return assistant_message
    
    def get_conversation_stats(self):
        """ëŒ€í™” í†µê³„"""
        return {
            "total_messages": len(self.conversation_history),
            "user_messages": len([m for m in self.conversation_history if m['role'] == 'user']),
            "assistant_messages": len([m for m in self.conversation_history if m['role'] == 'assistant'])
        }


def print_separator(char="â”€", length=60):
    """êµ¬ë¶„ì„ """
    print(char * length)


def print_message(role: str, content: str):
    """ë©”ì‹œì§€ ì¶œë ¥"""
    if role == "user":
        print(f"\nğŸ‘¤ You: {content}")
    else:
        print(f"\nğŸ¤– Assistant:")
        print(content)
    print_separator()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸ“š ë¸Œë ˆì¸ìŠ¤í† ë° ë§¤ë‰´ì–¼ (RAG í…ŒìŠ¤íŠ¸)                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• RAG ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ğŸ’¡

ğŸ’¬ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”:
   - "íŒ€ í˜‘ì—…ì— ì¢‹ì€ ë°©ë²•ì´ ë­ê°€ ìˆì„ê¹Œ?"
   - "ë¹ ë¥´ê²Œ ì•„ì´ë””ì–´ë¥¼ ë‚´ê³  ì‹¶ì–´"
   - "SWOT ë¶„ì„ì´ ë­ì•¼?"

ğŸ“ ëª…ë ¹ì–´:
   /help    - ë„ì›€ë§
   /stats   - ëŒ€í™” í†µê³„
   /clear   - ëŒ€í™” ì´ˆê¸°í™”
   /quit    - ì¢…ë£Œ
""")
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        print("â³ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        manual = BrainstormingManual()
        print(f"âœ… ì¤€ë¹„ ì™„ë£Œ! ({manual.collection.count()}ê°œ ê¸°ë²• ë¡œë“œë¨)\n")
        print_separator()
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   python chroma_loader.py ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
        sys.exit(1)
    
    # ëŒ€í™” ë£¨í”„
    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥ (í•œê¸€ ì…ë ¥ ì‹œ ë°±ìŠ¤í˜ì´ìŠ¤ ë¬¸ì œ í•´ê²°)
            try:
                user_input = input("\nğŸ’¬ You: ").strip()
            except EOFError:
                print("\n\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not user_input:
                continue
            
            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if user_input.startswith('/'):
                cmd = user_input.lower()
                
                if cmd == '/quit':
                    print("\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!")
                    break
                
                elif cmd == '/help':
                    print("""
ğŸ“š ì‚¬ìš© ê°€ì´ë“œ:

1ï¸âƒ£ ììœ ë¡œìš´ ì§ˆë¬¸
   - "íŒ€ íšŒì˜ì—ì„œ ì“¸ ìˆ˜ ìˆëŠ” ê¸°ë²•ì€?"
   - "í˜¼ì ì•„ì´ë””ì–´ ì •ë¦¬í•˜ëŠ” ë°©ë²•"
   - "ë¬¸ì œ í•´ê²° ë¸Œë ˆì¸ìŠ¤í† ë°"

2ï¸âƒ£ êµ¬ì²´ì ì¸ ìƒí™© ì„¤ëª…
   - "5ëª… íŒ€ìœ¼ë¡œ ì‹ ì œí’ˆ íšŒì˜ë¥¼ 1ì‹œê°„ í•´ì•¼í•´ìš”"
   - "ì˜¨ë¼ì¸ìœ¼ë¡œ ë¸Œë ˆì¸ìŠ¤í† ë°í•˜ë ¤ëŠ”ë° ì¶”ì²œí•´ì¤˜"

3ï¸âƒ£ íŠ¹ì • ê¸°ë²• ì§ˆë¬¸
   - "ë§ˆì¸ë“œë§µì´ ë­ì•¼?"
   - "SWOT ë¶„ì„ ë°©ë²• ì•Œë ¤ì¤˜"

ğŸ’¡ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë“¯ì´ ë¬¼ì–´ë³´ì„¸ìš”!
""")
                    continue
                
                elif cmd == '/stats':
                    stats = manual.get_conversation_stats()
                    print(f"""
ğŸ“Š ëŒ€í™” í†µê³„:
   - ì´ ë©”ì‹œì§€: {stats['total_messages']}ê°œ
   - ë‚´ ì§ˆë¬¸: {stats['user_messages']}ê°œ
   - AI ì‘ë‹µ: {stats['assistant_messages']}ê°œ
""")
                    continue
                
                elif cmd == '/clear':
                    manual.conversation_history = []
                    print("âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    continue
                
                else:
                    print("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. /helpë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”.")
                    continue
            
            # ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬
            print_separator()
            print("ğŸ¤– RAG ê²€ìƒ‰ ì¤‘...")
            
            # AI ì‘ë‹µ ìƒì„±
            response = manual.chat(user_input)
            
            # ì‘ë‹µ ì¶œë ¥
            print(f"\nğŸ¤– Assistant:\n{response}")
            print_separator()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()

