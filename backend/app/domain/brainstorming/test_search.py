"""
ë¸Œë ˆì¸ìŠ¤í† ë° RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì½˜ì†”ì—ì„œ ëŒ€í™”í˜•ìœ¼ë¡œ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
env_path = Path(__file__).parent.parent.parent.parent / '.env'
load_dotenv(env_path)

# í™˜ê²½ë³€ìˆ˜ ì²´í¬
if not os.getenv('OPENAI_API_KEY'):
    print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    sys.exit(1)

# ë…ë¦½ ì‹¤í–‰ì„ ìœ„í•œ ì„œë¹„ìŠ¤ ì„í¬íŠ¸
import chromadb
from chromadb.config import Settings
from openai import OpenAI
from typing import List, Dict, Optional


class BrainstormingService:
    """ë¸Œë ˆì¸ìŠ¤í† ë° RAG ê²€ìƒ‰ ì„œë¹„ìŠ¤ (í…ŒìŠ¤íŠ¸ìš© ë…ë¦½ ë²„ì „)"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.embedding_model = os.getenv('EMBEDDING_MODEL', 'text-embedding-3-large')
        self.llm_model = os.getenv('LLM_MODEL', 'gpt-4o')
        self.llm_temperature = float(os.getenv('LLM_TEMPERATURE', '0.7'))
        self.llm_max_tokens = int(os.getenv('LLM_MAX_TOKENS', '2000'))
        
        # ChromaDB ê²½ë¡œ ì„¤ì • - ë¸Œë ˆì¸ìŠ¤í† ë° ëª¨ë“ˆ ì „ìš©
        base_dir = Path(__file__).parent
        data_dir = base_dir / "data"
        self.persist_directory = str(data_dir / "chroma")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.chroma_client = chromadb.PersistentClient(
            path=self.persist_directory,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # ë¸Œë ˆì¸ìŠ¤í† ë° ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
        self.collection_name = "brainstorming_techniques"
        self.collection = self.chroma_client.get_collection(name=self.collection_name)
    
    def _embed_query(self, query: str) -> List[float]:
        """ì§ˆë¬¸ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
        response = self.openai_client.embeddings.create(
            model=self.embedding_model,
            input=query,
            encoding_format="float"
        )
        return response.data[0].embedding
    
    def search_techniques(self, query: str, n_results: int = 5, min_similarity: float = 0.0) -> List[Dict]:
        """ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ê²€ìƒ‰"""
        query_embedding = self._embed_query(query)
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )
        
        formatted_results = []
        for idx in range(len(results['ids'][0])):
            distance = results['distances'][0][idx]
            similarity = 1 - distance
            
            if similarity < min_similarity:
                continue
            
            metadata = results['metadatas'][0][idx]
            document = results['documents'][0][idx]
            
            formatted_results.append({
                "chunk_id": metadata['chunk_id'],
                "title": metadata['title'],
                "content": document,
                "similarity": round(similarity, 4),
                "metadata": {
                    "word_count": metadata.get('word_count', 0),
                    "char_count": metadata.get('char_count', 0),
                    "source_file": metadata.get('source_file', ''),
                    "embedding_model": metadata.get('embedding_model', '')
                }
            })
        
        return formatted_results
    
    def generate_suggestions(self, query: str, context_count: int = 3) -> Dict:
        """RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸Œë ˆì¸ìŠ¤í† ë° ì œì•ˆ ìƒì„±"""
        relevant_chunks = self.search_techniques(
            query=query,
            n_results=context_count,
            min_similarity=0.3
        )
        
        if not relevant_chunks:
            return {
                "query": query,
                "suggestions": "ê´€ë ¨ëœ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": []
            }
        
        context_text = "\n\n".join([
            f"[{chunk['title']}]\n{chunk['content']}"
            for chunk in relevant_chunks
        ])
        
        prompt = f"""ë‹¹ì‹ ì€ ë¸Œë ˆì¸ìŠ¤í† ë° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì•„ë˜ì˜ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²•ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ìƒí™©ì— ê°€ì¥ ì í•©í•œ ë°©ë²•ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.

<ì°¸ê³  ìë£Œ>
{context_text}

<ì‚¬ìš©ì ì§ˆë¬¸>
{query}

ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ:
1. ì´ ìƒí™©ì— ê°€ì¥ ì í•©í•œ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• 2-3ê°€ì§€ë¥¼ ì¶”ì²œí•˜ê³ 
2. ê° ê¸°ë²•ì„ ì–´ë–»ê²Œ ì ìš©í•˜ë©´ ì¢‹ì„ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
3. ì‹¤í–‰ ì‹œ ì£¼ì˜ì‚¬í•­ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.

ì¹œê·¼í•˜ê³  ì‹¤ìš©ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        response = self.openai_client.chat.completions.create(
            model=self.llm_model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¸Œë ˆì¸ìŠ¤í† ë°ê³¼ ì°½ì˜ì  ì‚¬ê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=self.llm_temperature,
            max_tokens=self.llm_max_tokens
        )
        
        suggestions = response.choices[0].message.content
        
        return {
            "query": query,
            "suggestions": suggestions,
            "sources": [
                {
                    "title": chunk['title'],
                    "chunk_id": chunk['chunk_id'],
                    "similarity": chunk['similarity']
                }
                for chunk in relevant_chunks
            ]
        }
    
    def get_technique_by_id(self, chunk_id: str) -> Optional[Dict]:
        """íŠ¹ì • ì²­í¬ IDë¡œ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ì¡°íšŒ"""
        try:
            result = self.collection.get(
                ids=[f"chunk_{chunk_id}"],
                include=["documents", "metadatas"]
            )
            
            if not result['ids']:
                return None
            
            metadata = result['metadatas'][0]
            document = result['documents'][0]
            
            return {
                "chunk_id": metadata['chunk_id'],
                "title": metadata['title'],
                "content": document,
                "metadata": {
                    "word_count": metadata.get('word_count', 0),
                    "char_count": metadata.get('char_count', 0),
                    "source_file": metadata.get('source_file', ''),
                    "embedding_model": metadata.get('embedding_model', '')
                }
            }
        except:
            return None
    
    def list_all_techniques(self) -> List[Dict]:
        """ëª¨ë“  ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ëª©ë¡ ì¡°íšŒ"""
        result = self.collection.get(include=["metadatas"])
        
        techniques = []
        for idx, chunk_id in enumerate(result['ids']):
            metadata = result['metadatas'][idx]
            techniques.append({
                "chunk_id": metadata['chunk_id'],
                "title": metadata['title'],
                "word_count": metadata.get('word_count', 0)
            })
        
        techniques.sort(key=lambda x: x['chunk_id'])
        return techniques


def print_separator(char="=", length=60):
    """êµ¬ë¶„ì„  ì¶œë ¥"""
    print(char * length)


def print_results(results, show_content=False):
    """ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥"""
    if not results:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“‹ {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
    print_separator("-")
    
    for idx, result in enumerate(results, 1):
        similarity_percent = result['similarity'] * 100
        
        print(f"\n{idx}. [{result['title']}]")
        print(f"   ì²­í¬ ID: {result['chunk_id']}")
        print(f"   ìœ ì‚¬ë„: {similarity_percent:.2f}%")
        print(f"   ê¸€ì ìˆ˜: {result['metadata']['char_count']}")
        
        if show_content:
            content_preview = result['content'][:200]
            if len(result['content']) > 200:
                content_preview += "..."
            print(f"   ë‚´ìš©: {content_preview}")
    
    print_separator("-")


def print_suggestions(result):
    """RAG ì œì•ˆ ì¶œë ¥"""
    print(f"\nğŸ’¡ ì§ˆë¬¸: {result['query']}")
    print_separator("-")
    print("\nğŸ“ AI ì œì•ˆ:")
    print(result['suggestions'])
    print_separator("-")
    print(f"\nğŸ“š ì°¸ê³ í•œ ìë£Œ ({len(result['sources'])}ê°œ):")
    for idx, source in enumerate(result['sources'], 1):
        print(f"   {idx}. {source['title']} (ìœ ì‚¬ë„: {source['similarity']*100:.1f}%)")


def test_basic_search(service: BrainstormingService):
    """ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print_separator()
    print("ğŸ” 1. ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print_separator()
    
    test_queries = [
        "íŒ€ í˜‘ì—…ì„ ìœ„í•œ ë¸Œë ˆì¸ìŠ¤í† ë°",
        "ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë¥¼ ë¹ ë¥´ê²Œ ë‚´ëŠ” ë°©ë²•",
        "ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì²´ê³„ì ì¸ ì ‘ê·¼"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” ê²€ìƒ‰: '{query}'")
        results = service.search_techniques(query, n_results=3)
        print_results(results, show_content=False)
        input("\nâ¸ï¸  ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")


def test_rag_suggestions(service: BrainstormingService):
    """RAG ì œì•ˆ í…ŒìŠ¤íŠ¸"""
    print_separator()
    print("ğŸ’¡ 2. RAG AI ì œì•ˆ í…ŒìŠ¤íŠ¸")
    print_separator()
    
    test_scenarios = [
        "ìš°ë¦¬ íŒ€ì€ ì‹ ì œí’ˆ ì•„ì´ë””ì–´ë¥¼ ì°¾ê³  ìˆì–´ìš”. 5ëª…ì˜ íŒ€ì›ì´ ìˆê³ , íšŒì˜ ì‹œê°„ì€ 1ì‹œê°„ì…ë‹ˆë‹¤.",
        "ë§ˆì¼€íŒ… ìº í˜ì¸ì„ ê¸°íší•´ì•¼ í•˜ëŠ”ë° ë§‰ë§‰í•´ìš”. ì–´ë–¤ ë°©ë²•ì´ ì¢‹ì„ê¹Œìš”?"
    ]
    
    for scenario in test_scenarios:
        print(f"\nğŸ“Œ ìƒí™©: {scenario}")
        print("\nâ³ AIê°€ ë¶„ì„ ì¤‘...")
        result = service.generate_suggestions(scenario, context_count=3)
        print_suggestions(result)
        input("\nâ¸ï¸  ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")


def interactive_mode(service: BrainstormingService):
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print_separator()
    print("ğŸ’¬ 3. ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ")
    print_separator()
    print("\nëª…ë ¹ì–´:")
    print("  - ê²€ìƒ‰ì–´ ì…ë ¥: ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ê²€ìƒ‰")
    print("  - 'rag [ì§ˆë¬¸]': AI ì œì•ˆ ë°›ê¸°")
    print("  - 'list': ëª¨ë“  ê¸°ë²• ëª©ë¡ ë³´ê¸°")
    print("  - 'id [ë²ˆí˜¸]': íŠ¹ì • ê¸°ë²• ìƒì„¸ë³´ê¸°")
    print("  - 'quit': ì¢…ë£Œ")
    print_separator()
    
    while True:
        try:
            user_input = input("\nğŸ” ì…ë ¥ >>> ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() == 'quit':
                print("\nğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if user_input.lower() == 'list':
                print("\nğŸ“š ëª¨ë“  ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²•:")
                techniques = service.list_all_techniques()
                for tech in techniques:
                    print(f"  [{tech['chunk_id']}] {tech['title']} ({tech['word_count']}ì)")
                continue
            
            if user_input.lower().startswith('id '):
                chunk_id = user_input[3:].strip()
                result = service.get_technique_by_id(chunk_id)
                if result:
                    print(f"\nğŸ“– [{result['title']}]")
                    print(f"   ì²­í¬ ID: {result['chunk_id']}")
                    print(f"   ê¸€ì ìˆ˜: {result['metadata']['char_count']}")
                    print(f"\n{result['content']}")
                else:
                    print(f"âŒ ì²­í¬ ID '{chunk_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            if user_input.lower().startswith('rag '):
                query = user_input[4:].strip()
                if query:
                    print("\nâ³ AIê°€ ë¶„ì„ ì¤‘...")
                    result = service.generate_suggestions(query, context_count=3)
                    print_suggestions(result)
                else:
                    print("âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: rag íŒ€ í˜‘ì—… ë°©ë²•")
                continue
            
            # ì¼ë°˜ ê²€ìƒ‰
            print(f"\nğŸ” ê²€ìƒ‰ ì¤‘: '{user_input}'")
            results = service.search_techniques(user_input, n_results=5)
            print_results(results, show_content=True)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸ§  ë¸Œë ˆì¸ìŠ¤í† ë° RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    print("â³ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    try:
        service = BrainstormingService()
        print("âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
        print(f"ğŸ“¦ ì»¬ë ‰ì…˜: {service.collection_name}")
        print(f"ğŸ”¢ ì €ì¥ëœ ê¸°ë²•: {service.collection.count()}ê°œ")
    except Exception as e:
        import traceback
        print(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("\nğŸ” ìƒì„¸ ì—ëŸ¬:")
        traceback.print_exc()
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   1. chroma_loader.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë²¡í„° DBë¥¼ êµ¬ì¶•í•˜ì„¸ìš”")
        print("   2. .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        sys.exit(1)
    
    # ë©”ë‰´
    while True:
        print("\n" + "=" * 60)
        print("í…ŒìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("  1. ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬)")
        print("  2. RAG AI ì œì•ˆ í…ŒìŠ¤íŠ¸ (ë¯¸ë¦¬ ì •ì˜ëœ ì‹œë‚˜ë¦¬ì˜¤)")
        print("  3. ëŒ€í™”í˜• ëª¨ë“œ (ììœ ë¡­ê²Œ ê²€ìƒ‰)")
        print("  4. ì „ì²´ í…ŒìŠ¤íŠ¸ (1 + 2 + 3)")
        print("  0. ì¢…ë£Œ")
        print("=" * 60)
        
        try:
            choice = input("\nì„ íƒ >>> ").strip()
            
            if choice == '0':
                print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            elif choice == '1':
                test_basic_search(service)
            elif choice == '2':
                test_rag_suggestions(service)
            elif choice == '3':
                interactive_mode(service)
            elif choice == '4':
                test_basic_search(service)
                test_rag_suggestions(service)
                interactive_mode(service)
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 0-4 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()

