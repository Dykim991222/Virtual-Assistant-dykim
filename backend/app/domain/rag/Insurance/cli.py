"""
Insurance RAG CLI ì¸í„°í˜ì´ìŠ¤

ë‹¨ì¼ ëª…ë ¹ì–´ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:
  # ë°©ë²• 1: __main__.py ì‚¬ìš© (ê¶Œì¥)
  python -m app.domain.rag.Insurance process internal_insurance/uploads
  python -m app.domain.rag.Insurance query "ìƒí•´ìš”ì¸ ì •ì˜"
  
  # ë°©ë²• 2: cli.py ì§ì ‘ ì‹¤í–‰
  python -m app.domain.rag.Insurance.cli process internal_insurance/uploads
  python -m app.domain.rag.Insurance.cli query "ìƒí•´ìš”ì¸ ì •ì˜"
  
  # ë°©ë²• 3: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
  python -m app.domain.rag.Insurance process app/domain/rag/Insurance/internal_insurance/uploads
"""

import sys
from pathlib import Path
import argparse

from .config import insurance_config
from .extractor.extract_pdf import extract_pdf
from .chunker import chunk_json
from .embedder import embed_chunks
from .vector_store import VectorStore
from .retriever import InsuranceRetriever
from .schemas import QueryRequest
from .utils import get_logger
from .performance import get_performance_monitor

logger = get_logger(__name__)


def main():
    """Insurance RAG CLI ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="Insurance RAG íŒŒì´í”„ë¼ì¸ CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # PDF ì²˜ë¦¬ (Extract â†’ Chunk â†’ Embed)
  python -m app.domain.rag.Insurance.cli process app/domain/rag/Insurance/internal_insurance/uploads
  python -m app.domain.rag.Insurance.cli process app/domain/rag/Insurance/internal_insurance/uploads/file.pdf
  
  # ì§ˆì˜ì‘ë‹µ
  python -m app.domain.rag.Insurance.cli query "ìƒí•´ìš”ì¸ ì •ì˜"
  python -m app.domain.rag.Insurance.cli query  # ëŒ€í™”í˜• ëª¨ë“œ
  
  # í†µê³„
  python -m app.domain.rag.Insurance.cli stats
  
  # ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
  python -m app.domain.rag.Insurance.cli reset
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´")
    
    # process ëª…ë ¹ì–´
    process_parser = subparsers.add_parser("process", help="PDF íŒŒì¼ ì²˜ë¦¬ (Extract â†’ Chunk â†’ Embed)")
    process_parser.add_argument("input_path", help="PDF íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    
    # upload ëª…ë ¹ì–´ (processì˜ ë³„ì¹­)
    upload_parser = subparsers.add_parser("upload", help="PDF íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ (processì™€ ë™ì¼)")
    upload_parser.add_argument("input_path", help="PDF íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    
    # query ëª…ë ¹ì–´
    query_parser = subparsers.add_parser("query", help="ì§ˆì˜ì‘ë‹µ")
    query_parser.add_argument("question", nargs="?", help="ì§ˆë¬¸ (ì—†ìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ)")
    query_parser.add_argument("--top-k", type=int, help="ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜")
    
    # stats ëª…ë ¹ì–´
    subparsers.add_parser("stats", help="Insurance RAG ì‹œìŠ¤í…œ í†µê³„")
    
    # reset ëª…ë ¹ì–´
    subparsers.add_parser("reset", help="Insurance ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # ëª…ë ¹ì–´ ì‹¤í–‰
    if args.command == "process":
        process_command(args.input_path)
    elif args.command == "upload":
        # uploadëŠ” processì˜ ë³„ì¹­
        process_command(args.input_path)
    elif args.command == "query":
        query_command(args.question, args.top_k)
    elif args.command == "stats":
        stats_command()
    elif args.command == "reset":
        reset_command()
    else:
        parser.print_help()
        sys.exit(1)


def process_command(input_path: str):
    """PDF ì²˜ë¦¬ ëª…ë ¹ì–´ (Extract â†’ Chunk â†’ Embed)"""
    input_path = Path(input_path)
    
    # ê²½ë¡œ ìë™ ë³´ì •: internal_docs â†’ internal_insurance
    if "internal_docs" in str(input_path):
        corrected_path = str(input_path).replace("internal_docs", "internal_insurance")
        print(f"âš ï¸  ê²½ë¡œ ìë™ ë³´ì •: {input_path} â†’ {corrected_path}")
        logger.info(f"ê²½ë¡œ ìë™ ë³´ì •: {input_path} â†’ {corrected_path}")
        input_path = Path(corrected_path)
    
    # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° Insurance ëª¨ë“ˆ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
    if not input_path.is_absolute():
        # internal_insuranceë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° Insurance í´ë” ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
        if str(input_path).startswith("internal_insurance"):
            insurance_dir = Path(__file__).parent
            input_path = insurance_dir / input_path
    
    if not input_path.exists():
        print(f"âŒ ì˜¤ë¥˜: ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        print(f"ğŸ’¡ íŒ: Insurance RAGëŠ” 'app/domain/rag/Insurance/internal_insurance/uploads' ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        logger.error(f"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        sys.exit(1)
    
    # PDF íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    if input_path.is_file():
        if input_path.suffix.lower() != ".pdf":
            print(f"âŒ ì˜¤ë¥˜: PDF íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {input_path}")
            logger.error(f"PDF íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {input_path}")
            sys.exit(1)
        pdf_files = [input_path]
    else:
        pdf_files = [p for p in input_path.iterdir() if p.suffix.lower() == ".pdf"]
    
    if not pdf_files:
        print(f"âŒ ì˜¤ë¥˜: PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        logger.error(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        sys.exit(1)
    
    logger.info(f"ì²˜ë¦¬í•  PDF íŒŒì¼: {len(pdf_files)}ê°œ")
    print(f"ğŸ“„ ì²˜ë¦¬í•  PDF íŒŒì¼: {len(pdf_files)}ê°œ\n")
    
    # ê° PDF íŒŒì¼ ì²˜ë¦¬
    success_count = 0
    fail_count = 0
    
    for idx, pdf_path in enumerate(pdf_files, 1):
        try:
            print(f"{'='*60}")
            print(f"[{idx}/{len(pdf_files)}] Processing: {pdf_path.name}")
            print(f"{'='*60}")
            
            # 1) Extract
            logger.info(f"1ë‹¨ê³„: PDF ì¶”ì¶œ ì‹œì‘ - {pdf_path.name}")
            print("1ï¸âƒ£  PDF ì¶”ì¶œ ì¤‘...")
            json_path = extract_pdf(str(pdf_path))
            logger.info(f"ì¶”ì¶œ ì™„ë£Œ: {json_path}")
            print(f"   âœ“ ì¶”ì¶œ ì™„ë£Œ: {json_path.name}")
            
            # 2) Chunk
            logger.info(f"2ë‹¨ê³„: ì²­í‚¹ ì‹œì‘ - {json_path.name}")
            print("2ï¸âƒ£  ì²­í‚¹ ì¤‘...")
            chunk_path = chunk_json(json_path)
            logger.info(f"ì²­í‚¹ ì™„ë£Œ: {chunk_path}")
            print(f"   âœ“ ì²­í‚¹ ì™„ë£Œ: {chunk_path.name}")
            
            # 3) Embed
            logger.info(f"3ë‹¨ê³„: ì„ë² ë”© ì‹œì‘ - {chunk_path.name}")
            print("3ï¸âƒ£  ì„ë² ë”© ì¤‘...")
            embed_chunks(chunk_path)
            logger.info(f"ì„ë² ë”© ì™„ë£Œ")
            print(f"   âœ“ ì„ë² ë”© ì™„ë£Œ (ChromaDB ì €ì¥ë¨)")
            
            success_count += 1
            print(f"âœ… {pdf_path.name} ì²˜ë¦¬ ì™„ë£Œ!\n")
            
        except Exception as e:
            fail_count += 1
            logger.exception(f"{pdf_path.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {pdf_path.name}", file=sys.stderr)
            print(f"   {str(e)}", file=sys.stderr)
            print()
            continue
    
    # ìµœì¢… ê²°ê³¼
    print(f"{'='*60}")
    print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼: ì„±ê³µ {success_count}ê°œ / ì‹¤íŒ¨ {fail_count}ê°œ")
    print(f"{'='*60}")
    
    if success_count > 0:
        print(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        logger.info(f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ / ì‹¤íŒ¨ {fail_count}ê°œ")
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì¶œë ¥
        monitor = get_performance_monitor()
        monitor.report()
    
    if fail_count > 0:
        sys.exit(1)


def query_command(question: str = None, top_k: int = None):
    """ì§ˆì˜ì‘ë‹µ ëª…ë ¹ì–´"""
    retriever = InsuranceRetriever()
    
    if question:
        # ë‹¨ì¼ ì§ˆë¬¸
        request = QueryRequest(query=question, top_k=top_k or insurance_config.RAG_TOP_K)
        response = retriever.query(request)
        
        print(f"\n{'='*60}")
        print(f"ì§ˆë¬¸: {question}")
        print(f"{'='*60}")
        print(f"\në‹µë³€:\n{response.answer}\n")
        
        if response.retrieved_chunks:
            print(f"ì°¸ê³  ë¬¸ì„œ ({len(response.retrieved_chunks)}ê°œ):")
            for i, chunk in enumerate(response.retrieved_chunks, 1):
                filename = chunk.metadata.get('filename', chunk.metadata.get('source', 'Unknown'))
                page_num = chunk.metadata.get('page_number', chunk.metadata.get('page', '?'))
                print(f"  {i}. {filename} (í˜ì´ì§€: {page_num}, ìœ ì‚¬ë„: {chunk.score:.4f})")
        else:
            print("âš ï¸  ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"\nì²˜ë¦¬ ì‹œê°„: {response.processing_time:.2f}ì´ˆ")
        print(f"{'='*60}\n")
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        print("=" * 60)
        print("Insurance RAG ì§ˆì˜ì‘ë‹µ (ëŒ€í™”í˜• ëª¨ë“œ)")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        print("=" * 60)
        
        while True:
            try:
                question = input("\nì§ˆë¬¸> ").strip()
                if question.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                    break
                
                if not question:
                    continue
                
                request = QueryRequest(query=question, top_k=top_k or insurance_config.RAG_TOP_K)
                response = retriever.query(request)
                
                print(f"\në‹µë³€:\n{response.answer}\n")
                
                if response.retrieved_chunks:
                    print(f"ì°¸ê³  ë¬¸ì„œ ({len(response.retrieved_chunks)}ê°œ):")
                    for i, chunk in enumerate(response.retrieved_chunks, 1):
                        filename = chunk.metadata.get('filename', chunk.metadata.get('source', 'Unknown'))
                        page_num = chunk.metadata.get('page_number', chunk.metadata.get('page', '?'))
                        print(f"  {i}. {filename} (í˜ì´ì§€: {page_num}, ìœ ì‚¬ë„: {chunk.score:.4f})")
                
            except KeyboardInterrupt:
                print("\n\nì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                logger.exception(f"ì§ˆì˜ì‘ë‹µ ì¤‘ ì˜¤ë¥˜: {e}")
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


def stats_command():
    """í†µê³„ ëª…ë ¹ì–´"""
    vector_store = VectorStore()
    count = vector_store.count_documents()
    
    print("=" * 60)
    print("Insurance RAG ì‹œìŠ¤í…œ í†µê³„")
    print("=" * 60)
    print(f"ì €ì¥ëœ ì´ ì²­í¬ ìˆ˜: {count}")
    print(f"ì»¬ë ‰ì…˜ ì´ë¦„: {insurance_config.CHROMA_COLLECTION_NAME}")
    print(f"ì„ë² ë”© ëª¨ë¸: {insurance_config.EMBEDDING_MODEL}")
    print(f"ë²ˆì—­ ëª¨ë¸: {insurance_config.TRANSLATION_MODEL}")
    print(f"LLM ëª¨ë¸: {insurance_config.OPENAI_MODEL}")
    print(f"Top-K: {insurance_config.RAG_TOP_K}")
    print(f"Threshold ë²”ìœ„: {insurance_config.RAG_MIN_SIMILARITY_THRESHOLD} ~ {insurance_config.RAG_MAX_SIMILARITY_THRESHOLD}")
    print(f"ì²­í¬ í¬ê¸°: {insurance_config.RAG_CHUNK_SIZE}")
    print(f"ì²­í¬ ì˜¤ë²„ë©: {insurance_config.RAG_CHUNK_OVERLAP}")
    print(f"ì²˜ë¦¬ëœ íŒŒì¼ ë””ë ‰í† ë¦¬: {insurance_config.PROCESSED_DIR}")
    print("=" * 60)


def reset_command():
    """ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ëª…ë ¹ì–´"""
    confirm = input("âš ï¸  Insurance ì»¬ë ‰ì…˜ì„ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ").strip().lower()
    
    if confirm != 'yes':
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    try:
        vector_store = VectorStore()
        vector_store.reset_collection()
        print("âœ… Insurance ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì™„ë£Œ!")
        logger.info("Insurance ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.exception(f"ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
