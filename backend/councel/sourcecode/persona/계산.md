# Persona 폴더 시간복잡도 및 공간복잡도 분석

## 목차
1. [response_generator.py](#1-response_generatorpy)
2. [search_engine.py](#2-search_enginepy)
3. [persona_manager.py](#3-persona_managerpy)
4. [rag_therapy.py](#4-rag_therapypy)
5. [therapy_logger.py](#5-therapy_loggerpy)
6. [전체 시스템 복잡도](#6-전체-시스템-복잡도)

---

## 1. response_generator.py

### 1.1 classify_input(user_input: str) -> str

**시간복잡도: O(k)**
- **설명**: `counseling_keywords` 리스트를 순회하며 키워드 매칭
- **계산식**: T(n) = k, 여기서 k = len(counseling_keywords)
- **최선의 경우**: O(1) - 첫 번째 키워드에서 매칭
- **최악의 경우**: O(k) - 모든 키워드를 확인해야 함
- **평균**: O(k/2) ≈ O(k)

**공간복잡도: O(1)**
- **설명**: 입력 문자열의 소문자 변환만 저장
- **계산식**: S(n) = O(1)

---

### 1.2 is_therapy_related(user_input: str) -> bool

**시간복잡도: O(k)**
- **설명**: `classify_input` 호출 → O(k)
- **계산식**: T(n) = O(k)

**공간복잡도: O(1)**

---

### 1.3 _generate_llm_only_response(...)

**시간복잡도: O(k + m)**
- **설명**: 
  - 최근 2개 히스토리에서 감정 추출: O(2 × 20 × m) = O(m), m = 평균 대화 텍스트 길이
  - 키워드 체크: O(k), k = len(counseling_keywords[:20]) = 20 (고정)
  - LLM API 호출: O(1)
- **계산식**: T(n) = O(k + m) = O(20 + m) = O(m)

**공간복잡도: O(h + m)**
- **설명**: 
  - messages 리스트: O(h)
  - emotion_context 문자열: O(m), m = 텍스트 길이
- **계산식**: S(n) = O(h + m)

---

### 1.4 generate_response_with_persona(...)

**시간복잡도: O(n + k + h)**
- **설명**: 
  - retrieved_chunks 순회: O(n), n = len(retrieved_chunks[:3]) = 최대 3
  - 감정 키워드 체크: O(k), k = len(counseling_keywords[:30])
  - 히스토리 처리: O(h), h = len(chat_history[-10])
  - LLM API 호출: O(1)
- **계산식**: T(n) = O(n + k + h) = O(3 + 30 + 10) = O(1) (상수 시간)
- **실제로는**: n, k, h가 고정되어 있으므로 O(1)로 근사 가능

**공간복잡도: O(n + h + c)**
- **설명**: 
  - used_chunks, used_chunks_detailed: O(n)
  - messages 리스트: O(h)
  - context 문자열: O(c), c = 청크 텍스트 길이 합
- **계산식**: S(n) = O(n + h + c)

---

## 2. search_engine.py

### 2.1 translate_to_english(text: str) -> str

**시간복잡도: O(1)**
- **설명**: LLM API 호출 (알고리즘 관점에서는 상수 시간)
- **계산식**: T(n) = O(1)
- **실제 네트워크 시간**: O(m), m = 텍스트 길이 (API 처리 시간)

**공간복잡도: O(m)**
- **설명**: 입력 텍스트와 응답 텍스트 저장
- **계산식**: S(n) = O(m)

---

### 2.2 create_query_embedding(query_text: str) -> List[float]

**시간복잡도: O(1)**
- **설명**: Embedding API 호출
- **계산식**: T(n) = O(1)

**공간복잡도: O(d)**
- **설명**: d차원 임베딩 벡터 저장 (text-embedding-3-large는 3072차원)
- **계산식**: S(n) = O(d) = O(3072) = O(1) (상수)

---

### 2.3 _distance_to_similarity(distance: float) -> float

**시간복잡도: O(1)**
- **설명**: 단순 산술 연산
- **계산식**: T(n) = O(1)

**공간복잡도: O(1)**

---

### 2.4 rerank_chunks(user_input: str, chunks: List[Dict]) -> List[Dict]

**시간복잡도: O(n + m)**
- **설명**: 
  - chunks 순회 및 텍스트 구성: O(n), n = len(chunks)
  - LLM API 호출: O(1)
  - 순위 파싱 및 재정렬: O(n)
- **계산식**: T(n) = O(n + m), m = user_input 길이
- **최선/최악**: 동일

**공간복잡도: O(n + m)**
- **설명**: 
  - chunks_text 문자열: O(n * c), c = 평균 청크 길이
  - reranked_chunks 리스트: O(n)
- **계산식**: S(n) = O(n * c + m)

---

### 2.5 _calculate_emotion_boost(user_input: str, chunk_text: str) -> float

**시간복잡도: O(k * (m + n))**
- **설명**: 
  - counseling_keywords 순회: O(k), k = len(counseling_keywords)
  - 각 키워드에 대해 문자열 검색: O(m + n)
    - m = len(user_input)
    - n = len(chunk_text)
- **계산식**: T(n) = O(k * (m + n))
- **최선의 경우**: O(k) - 첫 번째 키워드에서 매칭 후 조기 종료 가능
- **최악의 경우**: O(k * (m + n)) - 모든 키워드 확인

**공간복잡도: O(k)**
- **설명**: user_emotions set 저장
- **계산식**: S(n) = O(k)

---

### 2.6 _evaluate_search_quality(chunks: List[Dict]) -> Dict

**시간복잡도: O(n)**
- **설명**: 
  - chunks 순회: O(n), n = len(chunks)
  - 각 청크에 대해 유사도 계산: O(1)
  - sources set 구성: O(n)
- **계산식**: T(n) = O(n)

**공간복잡도: O(n)**
- **설명**: 
  - similarities 리스트: O(n)
  - sources set: O(n)
- **계산식**: S(n) = O(n)

---

### 2.7 _expand_query_with_llm(user_input: str) -> List[str]

**시간복잡도: O(1)**
- **설명**: LLM API 호출
- **계산식**: T(n) = O(1)

**공간복잡도: O(m + t)**
- **설명**: 
  - 입력 텍스트: O(m), m = len(user_input)
  - 확장된 검색어 리스트: O(t), t = 최대 5개
- **계산식**: S(n) = O(m + t) = O(m + 5) = O(m)

---

### 2.8 _iterative_search_with_query_expansion(user_input, max_iterations, n_results)

**시간복잡도: O(i * (n + q * n))**
- **설명**: 
  - 초기 검색: O(n)
  - 품질 평가: O(n)
  - 반복 루프 (최대 i-1회):
    - 쿼리 확장: O(1)
    - 확장된 쿼리로 재검색: O(q * n), q = 확장된 쿼리 개수 (최대 5)
    - 중복 제거: O(n)
    - 재평가: O(n)
  - Re-ranker: O(n)
- **계산식**: T(n) = O(n + (i-1) * (q * n + n)) = O(i * q * n)
- **최선의 경우**: O(n) - 첫 번째 검색에서 품질 충족
- **최악의 경우**: O(i * q * n) - 모든 반복 수행
- **실제 값**: i = 2, q = 5, n = 5 → O(2 * 5 * 5) = O(50) = O(1) (상수)

**공간복잡도: O(i * q * n)**
- **설명**: 
  - all_chunks 리스트: O(i * q * n)
  - seen_ids set: O(i * q * n)
- **계산식**: S(n) = O(i * q * n)

---

### 2.9 _hybrid_search(user_input: str, n_results: int) -> List[Dict]

**시간복잡도: O(n * (k + m))**
- **설명**: 
  - 임베딩 생성: O(1)
  - Vector DB 검색: O(n * 2) = O(n)
  - 결과 포맷팅 및 감정 가중치 계산: O(n * (k + m))
    - k = len(counseling_keywords)
    - m = 평균 청크 텍스트 길이
  - 정렬: O(n log n)
- **계산식**: T(n) = O(n * (k + m) + n log n)
- **실제로는**: n이 작으면 (n ≤ 10) O(n * (k + m))로 근사

**공간복잡도: O(n + d)**
- **설명**: 
  - retrieved_chunks 리스트: O(n)
  - 임베딩 벡터: O(d), d = 3072
- **계산식**: S(n) = O(n + d) = O(n)

---

### 2.10 retrieve_chunks(user_input: str, n_results: int, use_reranker: bool) -> List[Dict]

**시간복잡도: O(n)**
- **설명**: 
  - 임베딩 생성: O(1)
  - Vector DB 검색: O(n)
  - Re-ranker (선택적): O(n)
- **계산식**: T(n) = O(n)

**공간복잡도: O(n + d)**
- **설명**: 
  - retrieved_chunks 리스트: O(n)
  - 임베딩 벡터: O(d)
- **계산식**: S(n) = O(n + d) = O(n)

---

### 2.11 _get_max_similarity(retrieved_chunks: List[Dict]) -> float

**시간복잡도: O(n)**
- **설명**: chunks 순회하며 최대값 찾기
- **계산식**: T(n) = O(n)

**공간복잡도: O(1)**

---

## 3. persona_manager.py

### 3.1 __init__(...)

**시간복잡도: O(1)**
- **설명**: 
  - 캐시 로드 시도: O(1) (파일 읽기)
  - 기본 페르소나 생성: O(1)
  - 백그라운드 스레드 시작: O(1)
- **계산식**: T(n) = O(1)

**공간복잡도: O(1)**
- **설명**: 페르소나 문자열 저장
- **계산식**: S(n) = O(1)

---

### 3.2 _load_cached_persona() -> Optional[str]

**시간복잡도: O(1)**
- **설명**: JSON 파일 읽기
- **계산식**: T(n) = O(1)

**공간복잡도: O(p)**
- **설명**: p = 페르소나 텍스트 길이
- **계산식**: S(n) = O(p)

---

### 3.3 _save_persona_cache(persona: str)

**시간복잡도: O(p)**
- **설명**: JSON 파일 쓰기, p = 페르소나 텍스트 길이
- **계산식**: T(n) = O(p)

**공간복잡도: O(1)**

---

### 3.4 _generate_persona_from_rag() -> str

**시간복잡도: O(q * n + w)**
- **설명**: 
  - persona_queries 순회: O(q), q = 6 (고정)
  - 각 쿼리에 대해:
    - 임베딩 생성: O(1)
    - Vector DB 검색: O(n), n = 3 (고정)
  - 중복 제거: O(q * n)
  - 웹 검색: O(1) (API 호출)
  - LLM 페르소나 생성: O(1) (API 호출)
- **계산식**: T(n) = O(q * n + w) = O(6 * 3 + 1) = O(19) = O(1)
- **실제로는**: q와 n이 고정되어 있으므로 O(1)

**공간복잡도: O(q * n + p)**
- **설명**: 
  - all_chunks 리스트: O(q * n)
  - unique_chunks 리스트: O(q * n)
  - context 문자열: O(q * n * c + w), c = 평균 청크 길이, w = 웹 검색 결과 길이
  - 생성된 페르소나: O(p)
- **계산식**: S(n) = O(q * n * c + w + p)

---

### 3.5 _search_web_for_adler() -> str

**시간복잡도: O(1)**
- **설명**: LLM API 호출
- **계산식**: T(n) = O(1)

**공간복잡도: O(w)**
- **설명**: w = 웹 검색 결과 텍스트 길이
- **계산식**: S(n) = O(w)

---

## 4. rag_therapy.py

### 4.1 __init__(vector_db_path: str)

**시간복잡도: O(1)**
- **설명**: 
  - ChromaDB 클라이언트 초기화: O(1)
  - 컬렉션 로드: O(1)
  - 모듈 초기화: O(1)
- **계산식**: T(n) = O(1)

**공간복잡도: O(1)**
- **설명**: 클라이언트 및 컬렉션 참조 저장
- **계산식**: S(n) = O(1)

---

### 4.2 _save_qa_to_vectordb(user_query: str, llm_response: str)

**시간복잡도: O(m + n)**
- **설명**: 
  - 임베딩 생성: O(1)
  - JSON 생성: O(m + n), m = len(user_query), n = len(llm_response)
  - Vector DB 저장: O(1)
- **계산식**: T(n) = O(m + n)

**공간복잡도: O(m + n + d)**
- **설명**: 
  - qa_document 딕셔너리: O(m + n)
  - 임베딩 벡터: O(d)
- **계산식**: S(n) = O(m + n + d)

---

### 4.3 chat(user_input: str) -> Dict[str, Any]

**시간복잡도: O(i * q * n + k + h)**
- **설명**: 
  - 입력 분류: O(k), k = len(counseling_keywords)
  - 번역: O(1) (API 호출)
  - 반복 검색: O(i * q * n)
    - i = max_iterations = 2
    - q = 확장된 쿼리 개수 = 5
    - n = 검색 결과 수 = 5
  - 최고 유사도 계산: O(n)
  - 답변 생성: O(n + k + h)
    - n = retrieved_chunks 개수
    - k = counseling_keywords 개수
    - h = chat_history 길이
  - Self-learning 저장 (조건부): O(m + r), m = user_input 길이, r = response 길이
- **계산식**: T(n) = O(i * q * n + k + h + m + r)
- **실제 값**: i=2, q=5, n=5, k≈200, h≤10
  - T(n) = O(2 * 5 * 5 + 200 + 10) = O(50 + 210) = O(260) = O(1) (상수 시간으로 근사)

**공간복잡도: O(i * q * n + h + c)**
- **설명**: 
  - 검색 결과: O(i * q * n)
  - chat_history: O(h)
  - response 딕셔너리: O(c), c = 답변 및 메타데이터 크기
- **계산식**: S(n) = O(i * q * n + h + c)

---

### 4.4 summarize_chunk(chunk_text: str) -> str

**시간복잡도: O(1)**
- **설명**: 단순 문자열 슬라이싱
- **계산식**: T(n) = O(1)

**공간복잡도: O(1)**
- **설명**: 100자 문자열 반환
- **계산식**: S(n) = O(1)

---

## 5. therapy_logger.py

### 5.1 __init__(...)

**시간복잡도: O(1)**
- **설명**: 파일 경로 확인 및 모듈 임포트
- **계산식**: T(n) = O(1)

**공간복잡도: O(1)**

---

### 5.2 evaluate_response_quality(user_input, answer, retrieved_chunks) -> Dict

**시간복잡도: O(n + m + a)**
- **설명**: 
  - chunks_info 구성: O(n), n = len(retrieved_chunks[:2])
  - LLM API 호출: O(1)
  - JSON 파싱: O(e), e = 평가 결과 텍스트 길이
- **계산식**: T(n) = O(n + m + a + e) = O(n + m + a)
  - m = len(user_input)
  - a = len(answer)

**공간복잡도: O(n + m + a + e)**
- **설명**: 
  - chunks_info 문자열: O(n * c), c = 평균 청크 길이
  - evaluation_prompt: O(m + a + n * c)
  - 평가 결과 딕셔너리: O(e)
- **계산식**: S(n) = O(n * c + m + a + e)

---

### 5.3 log_conversation(user_input, response, retrieved_chunks, enable_scoring) -> Dict

**시간복잡도: O(n + m + a)**
- **설명**: 
  - 스코어링 (조건부): O(n + m + a)
  - 로그 저장: O(1)
- **계산식**: T(n) = O(n + m + a)

**공간복잡도: O(n + m + a + l)**
- **설명**: 
  - scoring_result: O(1) (고정 크기 딕셔너리)
  - 로그 데이터: O(l), l = 로그 항목 크기
- **계산식**: S(n) = O(n + m + a + l)

---

## 6. 전체 시스템 복잡도

### 6.1 주요 함수 호출 흐름

```
chat() 
  → classify_input() [O(k)]
  → translate_to_english() [O(1)]
  → _iterative_search_with_query_expansion() [O(i * q * n)]
    → retrieve_chunks() [O(n)]
    → _expand_query_with_llm() [O(1)]
    → _evaluate_search_quality() [O(n)]
    → rerank_chunks() [O(n)]
  → generate_response_with_persona() 또는 _generate_llm_only_response() [O(n + k + h)]
  → _save_qa_to_vectordb() (조건부) [O(m + r)]
```

### 6.2 전체 시간복잡도

**최선의 경우**: O(k + n + h)
- 첫 검색에서 품질 충족
- LLM 단독 모드 사용

**평균의 경우**: O(i * q * n + k + h)
- i = 2, q = 5, n = 5
- T(n) = O(2 * 5 * 5 + k + h) = O(50 + k + h)
- k ≈ 200, h ≤ 10
- T(n) = O(260) = O(1) (상수 시간으로 근사)

**최악의 경우**: O(i * q * n + k + h + m + r)
- 모든 반복 수행
- Self-learning 저장 포함

### 6.3 전체 공간복잡도

**평균**: O(i * q * n + h + c)
- 검색 결과: O(i * q * n) = O(50)
- 히스토리: O(h) = O(10)
- 응답 데이터: O(c)
- S(n) = O(50 + 10 + c) = O(c)

### 6.4 변수 정의

| 변수 | 의미 | 일반적인 값 |
|------|------|------------|
| k | counseling_keywords 개수 | ~200 |
| n | 검색 결과 수 (retrieved_chunks) | 3~5 |
| h | chat_history 길이 | ≤10 |
| i | max_iterations | 2 |
| q | 확장된 쿼리 개수 | ≤5 |
| m | user_input 길이 | 가변 |
| a | answer 길이 | 가변 |
| c | 청크 텍스트 평균 길이 | ~500 |
| d | 임베딩 벡터 차원 | 3072 |
| p | 페르소나 텍스트 길이 | ~2000 |

### 6.5 최적화 포인트

1. **키워드 검색 최적화**: 
   - 현재: O(k) 선형 검색
   - 개선: Trie 또는 해시셋 사용 → O(m), m = 입력 길이

2. **중복 제거 최적화**:
   - 현재: O(n) 리스트 순회
   - 개선: set 사용 → O(1) 평균

3. **검색 결과 캐싱**:
   - 동일한 쿼리에 대해 캐시 활용 → O(1)

4. **배치 처리**:
   - 여러 임베딩을 한 번에 생성 → API 호출 횟수 감소

---

## 7. 복잡도 계산 방법론

### 7.1 Big-O 표기법

**정의**: 함수의 증가율을 나타내는 점근적 표기법
- O(f(n)): 상한 (최악의 경우)
- Ω(f(n)): 하한 (최선의 경우)
- Θ(f(n)): 상한과 하한이 같을 때

**계산 규칙**:
1. 상수 무시: O(2n) = O(n)
2. 낮은 차수 무시: O(n² + n) = O(n²)
3. 곱셈: O(f(n)) × O(g(n)) = O(f(n) × g(n))
4. 덧셈: O(f(n)) + O(g(n)) = O(max(f(n), g(n)))

### 7.2 시간복잡도 계산 단계

1. **입력 크기 파악**: n, m, k 등 변수 정의
2. **주요 연산 식별**: 반복문, 재귀, API 호출 등
3. **중첩 구조 분석**: 이중 루프 → O(n²)
4. **최악/최선/평균 분석**: 조건부 분기 고려
5. **Big-O 표기법 적용**: 상수 및 낮은 차수 제거

### 7.3 공간복잡도 계산 단계

1. **입력 공간**: 입력 데이터 크기
2. **보조 공간**: 알고리즘 실행 중 추가 메모리
3. **출력 공간**: 결과 데이터 크기
4. **총 공간**: 입력 + 보조 + 출력

### 7.4 실제 예시: rerank_chunks()

```python
def rerank_chunks(user_input: str, chunks: List[Dict]) -> List[Dict]:
    # 1. chunks 순회: O(n)
    chunks_text = "\n\n".join([
        f"[청크 {i+1}]\n{chunk['text'][:300]}..." 
        for i, chunk in enumerate(chunks)  # O(n)
    ])
    
    # 2. LLM API 호출: O(1) (알고리즘 관점)
    response = self.openai_client.chat.completions.create(...)
    
    # 3. 순위 파싱: O(n)
    ranked_indices = [int(x) - 1 for x in re.findall(r'\d+', ranking_text)]
    
    # 4. 재정렬: O(n)
    reranked_chunks = [chunks[idx] for idx in valid_indices]
    
    # 총 시간복잡도: O(n) + O(1) + O(n) + O(n) = O(n)
```

---

## 8. 참고사항

### 8.1 API 호출의 복잡도

- **알고리즘 관점**: O(1) - 단일 연산으로 간주
- **실제 성능**: 네트워크 지연, API 처리 시간 등으로 인해 실제로는 O(m) 이상
- **본 문서**: 알고리즘 복잡도 중심으로 분석

### 8.2 Vector DB 검색 복잡도

- **ChromaDB**: 근사 최근접 이웃 검색 (ANN)
- **이론적 복잡도**: O(n log n) 또는 O(n) (인덱스 구조에 따라)
- **본 문서**: O(n)으로 근사 (n = 검색 결과 수)

### 8.3 문자열 연산 복잡도

- **문자열 검색 (in 연산자)**: O(m + n) - KMP 알고리즘
- **문자열 연결**: O(m + n) - 새 문자열 생성
- **문자열 슬라이싱**: O(k) - k = 슬라이스 길이

---

## 9. 요약

### 9.1 핵심 함수별 복잡도 요약

| 함수 | 시간복잡도 | 공간복잡도 | 비고 |
|------|-----------|-----------|------|
| `classify_input` | O(k) | O(1) | k ≈ 200 |
| `retrieve_chunks` | O(n) | O(n) | n ≤ 5 |
| `_iterative_search_with_query_expansion` | O(i * q * n) | O(i * q * n) | i=2, q=5, n=5 |
| `generate_response_with_persona` | O(n + k + h) | O(n + h + c) | n≤3, k≈200, h≤10 |
| `chat` | O(i * q * n + k + h) | O(i * q * n + h + c) | 전체 시스템 |

### 9.2 실용적 관점

- **대부분의 함수**: 상수 시간 또는 선형 시간
- **실제 성능 병목**: API 호출 (네트워크 지연)
- **메모리 사용**: 검색 결과와 히스토리 관리에 집중
- **확장성**: n, k, h가 고정되어 있어 확장성 양호

---

**작성일**: 2025.12.01  
**작성자**: AI Assistant  
**목적**: Persona 폴더 내 파일들의 시간복잡도 및 공간복잡도 분석 및 학습 자료

