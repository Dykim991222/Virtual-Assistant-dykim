# 시간복잡도 및 공간복잡도 분석 결과

## 개요
이 문서는 `automatic_save` 폴더 내의 Python 스크립트들과 `automatic_save.py` 파일의 시간복잡도와 공간복잡도를 분석한 결과입니다.

---

## 1. save_to_vectordb.py

### 주요 함수별 복잡도 분석

#### 1.1 `VectorDBManager.__init__()`
- **시간복잡도**: O(1)
- **공간복잡도**: O(1)
- **설명**: ChromaDB 클라이언트 초기화는 상수 시간이 소요됩니다.

#### 1.2 `load_embedding_file(filepath: Path)`
- **시간복잡도**: O(N)
- **공간복잡도**: O(N)
- **설명**: 
  - N: JSON 파일의 크기 (문자 수)
  - 파일을 읽고 JSON 파싱하는 과정에서 O(N) 시간과 공간이 필요합니다.

#### 1.3 `create_or_get_collection(collection_name: str)`
- **시간복잡도**: O(1)
- **공간복잡도**: O(1)
- **설명**: 컬렉션 생성/조회는 상수 시간이 소요됩니다.

#### 1.4 `save_to_collection(collection_name, data, batch_size=1000)`
- **시간복잡도**: O(N + M)
- **공간복잡도**: O(N + M)
- **설명**:
  - N: 저장할 데이터 항목 수
  - M: 기존 데이터 항목 수
  - 기존 ID 확인: O(M) - `collection.get()` 호출
  - 데이터 준비: O(N) - 모든 데이터 순회
  - 배치 저장: O(N) - N/batch_size 번의 배치 저장
  - 공간: 기존 ID 집합 O(M) + 새 데이터 리스트 O(N)

#### 1.5 `verify_collection(collection_name: str)`
- **시간복잡도**: O(1)
- **공간복잡도**: O(1)
- **설명**: 컬렉션 정보 조회는 상수 시간이 소요됩니다.

#### 1.6 `main()`
- **시간복잡도**: O(F × N + M)
- **공간복잡도**: O(F × N + M)
- **설명**:
  - F: 임베딩 파일 개수
  - N: 각 파일의 평균 데이터 항목 수
  - M: 기존 Vector DB의 데이터 항목 수
  - 파일 로드: O(F × N)
  - 데이터 저장: O(F × N + M)

### 전체 복잡도 요약
- **최악의 경우 시간복잡도**: O(F × N + M)
- **최악의 경우 공간복잡도**: O(F × N + M)
- **F**: 임베딩 파일 개수
- **N**: 총 데이터 항목 수
- **M**: 기존 Vector DB 데이터 항목 수

---

## 2. create_chunk_files.py

### 주요 함수별 복잡도 분석

#### 2.1 `count_tokens(text: str)`
- **시간복잡도**: O(T)
- **공간복잡도**: O(T)
- **설명**:
  - T: 텍스트의 토큰 수
  - tiktoken 인코딩은 텍스트 길이에 비례합니다.

#### 2.2 `extract_text_from_pdf(pdf_path: Path)`
- **시간복잡도**: O(P × L)
- **공간복잡도**: O(P × L)
- **설명**:
  - P: PDF 페이지 수
  - L: 평균 페이지당 문자 수
  - 각 페이지를 순회하며 텍스트 추출: O(P × L)
  - 정규식 처리: O(P × L)

#### 2.3 `clean_pdf_text(text: str)`
- **시간복잡도**: O(T)
- **공간복잡도**: O(T)
- **설명**:
  - T: 텍스트 길이 (문자 수)
  - 여러 정규식 패턴 적용: O(T)
  - 줄 단위 처리: O(L) (L: 줄 수)
  - 전체적으로 O(T)로 근사 가능

#### 2.4 `split_into_parents(section_content: str)`
- **시간복잡도**: O(T + P)
- **공간복잡도**: O(T)
- **설명**:
  - T: 섹션 텍스트의 토큰 수
  - P: 문단 개수
  - 토큰 계산: O(T)
  - 문단 분할: O(P)
  - 줄 단위 분할 (최악의 경우): O(L) (L: 줄 수)
  - 전체적으로 O(T + P)로 근사

#### 2.5 `split_parent_into_children(parent_content: str)`
- **시간복잡도**: O(T + P)
- **공간복잡도**: O(T)
- **설명**:
  - T: Parent 텍스트의 토큰 수
  - P: 문단 개수
  - `split_into_parents()`와 동일한 로직이므로 복잡도도 동일합니다.

#### 2.6 `process_file(filepath: Path, metadata: Dict)`
- **시간복잡도**: O(P × L + T + C)
- **공간복잡도**: O(P × L + T)
- **설명**:
  - P: PDF 페이지 수
  - L: 평균 페이지당 문자 수
  - T: 전체 텍스트 토큰 수
  - C: 생성된 Parent 청크 수
  - PDF 추출: O(P × L)
  - 텍스트 정제: O(P × L)
  - Parent 분할: O(T + P)
  - Child 분할: O(T + C)

#### 2.7 `create_chunk_objects(parent_child_data, metadata, base_id)`
- **시간복잡도**: O(P × C_avg)
- **공간복잡도**: O(P × C_avg)
- **설명**:
  - P: Parent 청크 수
  - C_avg: Parent당 평균 Child 청크 수
  - 각 Parent와 Child에 대해 객체 생성: O(P × C_avg)

#### 2.8 `process_single_file(filepath: Path, output_dir: Path)`
- **시간복잡도**: O(P × L + T + P × C_avg)
- **공간복잡도**: O(P × L + P × C_avg)
- **설명**:
  - `process_file()` + `create_chunk_objects()`의 복잡도 합

#### 2.9 `process_directory(input_dir, output_dir, file_pattern, save_individually)`
- **시간복잡도**: O(F × (P × L + T + P × C_avg))
- **공간복잡도**: O(P × L + P × C_avg) (개별 저장 시)
- **설명**:
  - F: 처리할 파일 개수
  - 개별 저장 시: 각 파일을 독립적으로 처리하므로 공간복잡도는 단일 파일 처리와 동일
  - 단일 파일 저장 시: 모든 파일의 청크를 메모리에 유지하므로 O(F × P × C_avg)

### 전체 복잡도 요약
- **최악의 경우 시간복잡도**: O(F × (P × L + T + P × C_avg))
- **최악의 경우 공간복잡도**: 
  - 개별 저장: O(P × L + P × C_avg)
  - 단일 파일 저장: O(F × P × C_avg)
- **F**: PDF 파일 개수
- **P**: 평균 페이지 수
- **L**: 평균 페이지당 문자 수
- **T**: 평균 텍스트 토큰 수
- **C_avg**: Parent당 평균 Child 청크 수

---

## 3. create_openai_embeddings.py

### 주요 함수별 복잡도 분석

#### 3.1 `load_chunks(file_path: str)`
- **시간복잡도**: O(N)
- **공간복잡도**: O(N)
- **설명**:
  - N: JSON 파일의 크기 (문자 수)
  - 파일 읽기 및 JSON 파싱: O(N)

#### 3.2 `create_embeddings(chunks, model_name)`
- **시간복잡도**: O(N × E)
- **공간복잡도**: O(N × E)
- **설명**:
  - N: 청크 개수
  - E: 임베딩 벡터 차원 (text-embedding-3-large는 3072차원)
  - 배치 처리: O(N/B) 번의 API 호출 (B: BATCH_SIZE=100)
  - 각 API 호출 시간은 배치 크기에 비례하므로 전체적으로 O(N × E)
  - 공간: 모든 임베딩 벡터 저장 O(N × E)

#### 3.3 `save_embeddings(chunks, embeddings, output_path)`
- **시간복잡도**: O(N × E)
- **공간복잡도**: O(N × E)
- **설명**:
  - N: 청크 개수
  - E: 임베딩 벡터 차원
  - 청크와 임베딩 결합: O(N)
  - JSON 직렬화: O(N × E)

#### 3.4 `main()`
- **시간복잡도**: O(F × N × E)
- **공간복잡도**: O(N × E) (한 번에 하나의 파일만 처리)
- **설명**:
  - F: 청크 파일 개수
  - N: 각 파일의 평균 청크 개수
  - E: 임베딩 벡터 차원
  - 각 파일을 순차적으로 처리하므로 공간복잡도는 단일 파일 처리와 동일

### 전체 복잡도 요약
- **최악의 경우 시간복잡도**: O(F × N × E)
- **최악의 경우 공간복잡도**: O(N × E)
- **F**: 청크 파일 개수
- **N**: 평균 청크 개수
- **E**: 임베딩 벡터 차원 (3072 for text-embedding-3-large)

**참고**: 실제 API 호출 시간은 네트워크 지연과 OpenAI 서버 응답 시간에 의존하므로, 이론적 복잡도보다 실제 실행 시간이 더 클 수 있습니다.

---

## 4. automatic_save.py

### 주요 함수별 복잡도 분석

#### 4.1 `AutomaticSaveManager.__init__()`
- **시간복잡도**: O(1)
- **공간복잡도**: O(1)
- **설명**: 경로 설정 및 초기화는 상수 시간이 소요됩니다.

#### 4.2 `check_folder_and_files(folder_path, file_pattern)`
- **시간복잡도**: O(F)
- **공간복잡도**: O(F)
- **설명**:
  - F: 파일 개수
  - 폴더 존재 확인: O(1)
  - 파일 목록 가져오기: O(F) - `glob()` 호출
  - 공간: 파일 목록 저장 O(F)

#### 4.3 `create_folder_if_not_exists(folder_path)`
- **시간복잡도**: O(1)
- **공간복잡도**: O(1)
- **설명**: 폴더 생성은 상수 시간이 소요됩니다. (디렉토리 구조 깊이는 고려하지 않음)

#### 4.4 `rollback()`
- **시간복잡도**: O(D × S)
- **공간복잡도**: O(1)
- **설명**:
  - D: 생성된 디렉토리 개수
  - S: 각 디렉토리의 평균 크기 (파일/하위 디렉토리 수)
  - 각 디렉토리 삭제: O(S)
  - 전체: O(D × S)

#### 4.5 `run_script(script_path)`
- **시간복잡도**: O(1) + T_script
- **공간복잡도**: O(1)
- **설명**:
  - subprocess 실행 오버헤드: O(1)
  - T_script: 실제 스크립트 실행 시간 (호출되는 스크립트의 복잡도에 의존)
  - 이 함수 자체의 복잡도는 O(1)이지만, 실제 실행 시간은 호출되는 스크립트에 의존합니다.

#### 4.6 `step1_create_chunks()`
- **시간복잡도**: O(F) + T_chunk
- **공간복잡도**: O(F)
- **설명**:
  - F: 청크 파일 개수
  - 파일 존재 확인: O(F)
  - 스크립트 실행: T_chunk (create_chunk_files.py의 실행 시간)
  - 공간: 파일 목록 저장 O(F)

#### 4.7 `step2_create_embeddings()`
- **시간복잡도**: O(F) + T_embedding
- **공간복잡도**: O(F)
- **설명**:
  - F: 임베딩 파일 개수
  - 파일 존재 확인: O(F)
  - 스크립트 실행: T_embedding (create_openai_embeddings.py의 실행 시간)
  - 공간: 파일 목록 저장 O(F)

#### 4.8 `step3_save_to_vectordb()`
- **시간복잡도**: O(1) + T_vectordb
- **공간복잡도**: O(1)
- **설명**:
  - 폴더 존재 확인: O(1)
  - ChromaDB 컬렉션 확인: O(1)
  - 스크립트 실행: T_vectordb (save_to_vectordb.py의 실행 시간)

#### 4.9 `run()`
- **시간복잡도**: O(F) + T_chunk + T_embedding + T_vectordb
- **공간복잡도**: O(F)
- **설명**:
  - F: 파일 개수 (청크 파일 또는 임베딩 파일)
  - 각 단계의 파일 확인: O(F)
  - 세 단계 순차 실행:
    - T_chunk: create_chunk_files.py 실행 시간
    - T_embedding: create_openai_embeddings.py 실행 시간
    - T_vectordb: save_to_vectordb.py 실행 시간
  - 공간: 파일 목록 저장 O(F)

#### 4.10 `automatic_save()`
- **시간복잡도**: O(F) + T_chunk + T_embedding + T_vectordb
- **공간복잡도**: O(F)
- **설명**: `AutomaticSaveManager` 인스턴스 생성 O(1) + `run()` 호출

### 전체 복잡도 요약
- **최악의 경우 시간복잡도**: O(F) + T_chunk + T_embedding + T_vectordb
- **최악의 경우 공간복잡도**: O(F)
- **F**: 파일 개수 (청크 파일 또는 임베딩 파일)
- **T_chunk**: create_chunk_files.py 실행 시간
- **T_embedding**: create_openai_embeddings.py 실행 시간
- **T_vectordb**: save_to_vectordb.py 실행 시간

**참고**: 
- `automatic_save.py`는 통합 관리자 역할을 하며, 실제 작업은 하위 스크립트에서 수행됩니다.
- 자체 복잡도는 주로 파일 시스템 작업(O(F))에 의존하며, 실제 처리 시간은 호출되는 스크립트의 복잡도에 의존합니다.
- 각 단계는 순차적으로 실행되므로, 전체 시간은 세 단계의 실행 시간 합과 같습니다.

---

## 전체 파이프라인 복잡도 분석

### 파이프라인 실행 순서
1. `automatic_save.py` → 통합 프로세스 관리
2. `create_chunk_files.py` → 청크 파일 생성
3. `create_openai_embeddings.py` → 임베딩 생성
4. `save_to_vectordb.py` → Vector DB 저장

### 전체 시간복잡도

#### automatic_save.py를 통한 통합 실행 시
- **시간복잡도**: O(F) + O(F × (P × L + T + P × C_avg)) + O(F × N × E) + O(F × N + M)
- **설명**:
  - automatic_save.py 오버헤드: O(F) - 파일 존재 확인
  - 청크 생성: O(F × (P × L + T + P × C_avg))
  - 임베딩 생성: O(F × N × E)
  - Vector DB 저장: O(F × N + M)
  - 일반적으로 임베딩 생성 단계가 가장 시간이 오래 걸립니다.
  - automatic_save.py의 오버헤드는 상대적으로 작습니다.

### 전체 공간복잡도

#### automatic_save.py를 통한 통합 실행 시
- **공간복잡도**: O(max(F, P × L + P × C_avg, N × E, F × N + M))
- **설명**:
  - automatic_save.py: O(F) - 파일 목록 저장
  - 청크 생성: O(P × L + P × C_avg) (개별 저장 시)
  - 임베딩 생성: O(N × E)
  - Vector DB 저장: O(F × N + M)
  - 각 단계는 순차적으로 실행되므로 최대값이 전체 공간복잡도입니다.
  - 일반적으로 Vector DB 저장 단계가 가장 많은 공간을 사용합니다.

---

## 변수 정의 정리

### 공통 변수
- **F**: 파일 개수 (PDF 파일 또는 청크 파일)
- **N**: 데이터 항목/청크 개수
- **M**: 기존 Vector DB의 데이터 항목 수

### create_chunk_files.py 관련
- **P**: PDF 페이지 수
- **L**: 평균 페이지당 문자 수
- **T**: 텍스트 토큰 수
- **C_avg**: Parent당 평균 Child 청크 수

### create_openai_embeddings.py 관련
- **E**: 임베딩 벡터 차원 (3072 for text-embedding-3-large)
- **B**: 배치 크기 (100)

### automatic_save.py 관련
- **F**: 파일 개수 (청크 파일 또는 임베딩 파일)
- **D**: 생성된 디렉토리 개수 (롤백 시)
- **S**: 각 디렉토리의 평균 크기 (파일/하위 디렉토리 수)
- **T_chunk**: create_chunk_files.py 실행 시간
- **T_embedding**: create_openai_embeddings.py 실행 시간
- **T_vectordb**: save_to_vectordb.py 실행 시간

---

## 최적화 고려사항

### 시간복잡도 최적화
1. **배치 처리**: 모든 스크립트에서 배치 처리를 사용하여 I/O 오버헤드를 줄입니다.
2. **병렬 처리**: 여러 파일을 병렬로 처리할 수 있지만, 현재 구현은 순차 처리입니다.
3. **캐싱**: 중간 결과물(청크 파일, 임베딩 파일)을 캐싱하여 재실행 시 시간을 절약합니다. `automatic_save.py`는 이미 파일 존재 여부를 확인하여 불필요한 재실행을 방지합니다.
4. **조건부 실행**: `automatic_save.py`는 각 단계에서 파일/컬렉션 존재 여부를 확인하여 이미 완료된 단계를 건너뜁니다.

### 공간복잡도 최적화
1. **스트리밍 처리**: 대용량 파일을 한 번에 메모리에 로드하지 않고 스트리밍으로 처리할 수 있습니다.
2. **개별 파일 저장**: `create_chunk_files.py`에서 개별 파일로 저장하면 메모리 사용량을 줄일 수 있습니다.
3. **가비지 컬렉션**: 각 단계 완료 후 명시적으로 가비지 컬렉션을 호출하여 메모리를 해제할 수 있습니다.
4. **롤백 최적화**: `automatic_save.py`의 `rollback()` 함수는 생성된 디렉토리만 추적하므로 메모리 사용량이 적습니다.

---

## 결론

각 스크립트의 복잡도는 입력 데이터 크기에 선형적으로 비례합니다. `automatic_save.py`는 통합 관리자 역할을 하며, 실제 작업은 하위 스크립트에서 수행됩니다. 자체 복잡도는 주로 파일 시스템 작업에 의존하며(O(F)), 실제 처리 시간은 호출되는 스크립트의 복잡도에 의존합니다.

가장 시간이 오래 걸리는 단계는 임베딩 생성 단계이며, 특히 OpenAI API 호출 시 네트워크 지연이 추가로 발생할 수 있습니다. 공간복잡도는 각 단계에서 필요한 최대 메모리 사용량에 의해 결정되며, 순차 실행으로 인해 전체 파이프라인의 공간복잡도는 각 단계의 최대값과 같습니다. 일반적으로 Vector DB 저장 단계가 가장 많은 공간을 사용합니다.

